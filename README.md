# LayerXTR
[![PyPI version](https://badge.fury.io/py/layerxtr.svg)](https://badge.fury.io/py/layerxtr)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Downloads](https://static.pepy.tech/badge/layerxtr)](https://pepy.tech/project/layerxtr)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-blue)](https://www.linkedin.com/in/eugene-evstafev-716669181/)

Extract and organize detailed layer information from image editing descriptions.

## Overview

LayerXTR enables users to process textual descriptions of image layers and return a structured output listing each layer with its attributes. This tool helps streamline workflows for graphic designers, digital artists, and content creators by automating the extraction of layer details from textual descriptions, making it easier to replicate or modify image compositions programmatically.

## Installation

```bash
pip install layerxtr
```

## Usage

```python
from layerxtr import layerxtr

user_input = "background: sky, foreground: trees, objects: birds"
response = layerxtr(user_input)
print(response)
```
### Input Parameters
- `user_input`: `str` - the user input text to process
- `llm`: `Optional[BaseChatModel]`: the langchain llm instance to use, if not provided the default ChatLLM7 will be used.
- `api_key`: `Optional[str]`: the api key for llm7, if not provided will use default LLM7 key

Note: This package uses the ChatLLM7 from langchain_llm7 by default. Developers can safely pass their own llm instance if they want to use another LLM, via passing it like `layerxtr(user_input, llm=their_llm_instance)`.

### Passing Your Own LLM Instance

For example, to use the openai:
```python
from langchain_openai import ChatOpenAI
from layerxtr import layerxtr

llm = ChatOpenAI()
response = layerxtr(user_input, llm=llm)
```
or for example to use the anthropic:
```python
from langchain_anthropic import ChatAnthropic
from layerxtr import layerxtr

llm = ChatAnthropic()
response = layerxtr(user_input, llm=llm)
```
or google:
```python
from langchain_google_genai import ChatGoogleGenerativeAI
from layerxtr import layerxtr

llm = ChatGoogleGenerativeAI()
response = layerxtr(user_input, llm=llm)
```
If you need higher rate limits for LLM7, you can pass your own api_key via environment variable `LLM7_API_KEY` or via passing it directly like `layerxtr(user_input, api_key="their_api_key")`. You can get a free api key by registering at https://token.llm7.io/

## Rate Limits
The default rate limits for LLM7 free tier are sufficient for most use cases of this package.

## Issues
Find issues and submit new ones: https://github.com/chigwell/layerxtr/issues

## Author
Eugene Evstafev
hi@euegne.plus